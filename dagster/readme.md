# Dagster orchestration prototype

This is a prototype of dagster orchestration to demonstrate:

Step (1) Ingestion of sample local csv file and loading of sample table to Bigquery using Meltano

Step (2) GX validation of the Olist tables in Bigquery at brazilian-e-commerce-team-3.BET_Team3

Step (3) Transformation to sample dim and fact table using dbt

Step (4) GX validation of Olist dim and fact tables in Bigquery at brazilian-e-commerce-team-3.BET_Team3

![Prototype Dagster Lineage](/docs/dagster_lineage.png)

Step (1) and (3) currently uses BQ lkk-dsai.GX_Meltano_Test and lkk-dsai.GX_DBT_Test which are accessible by the author's BQ service account.

They can be replaced by actual Meltano ingestion/loading of data tables to BQ Brazilian-e-commerce-team-3.BET_Team3 and also DBT transformation to create the dim and fact tables.

Step (2) and (4) are validating the data, dim and fact tables already in BQ Brazilian-e-commerce-team-3.BET_Team3

## Protoype Development Guide:
### 1) Meltano
All files relating to Meltano are located at <your path>/dagster/GX_Meltano_Test

  ```bash
bash
cd <your path>/dagster/GX_Meltano_Test
```

1.1) meltano.yml:

  1.1.1) Extractor:

  a) customer_100.csv is provided as the csv to be used by extractor tap-csv and has customer_id as key.

  b) Replace path: (currently full local path where csv file is located)

  ```bash
# meltano.yml

  extractors:
  - name: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
    config:
      files:
        - entity: customer_100
          path: <your path>/customer_100.csv
          keys: [customer_id]
          elimiter: ","
          encoding: "utf-8"
          format: "csv"
```

  1.1.2) Loader:

  a) Replace project (currently lkk-dsai)

  b) Replace dataset (currently GX_Meltano_Test)

  c) Replace credentials_path (currently JSON from service account that can access lkk-dsai)

*** Bigquery loader requires the JSON from the service account that can access the BQ project and dataset ***

  ```bash
# meltano.yml

  loaders:
  - name: target-bigquery
    variant: z3z1ma
    pip_url: git+https://github.com/z3z1ma/target-bigquery.git
    config:
      project: <your BQ project id>
      dataset: <your BQ dataset name>
      credentials_path: <your path>/<your BQ service account>.json
      method: batch_job
      denormalized: true
      flattening_enabled: true
      flattening_max_depth: 1
```
### Test Meltano
After making changes to the above, it is very important to test and debug your meltano before going to the next stage.
  ```bash
bash

cd <your path>/dagster/GX_Meltano_Test
meltano run tap-csv target-csv

```
Check that the BQ project.dataset has correctly created customer_100 before you continue.

### 2) GX Validate Meltano
All files relating to the validation of Meltano tables are located at <your path>/dagster/gx/dataset

  ```bash
bash
cd <your path>/dagster/gx/dataset
```

The script for GX does not validate the customer_100 table that you had created above.

Instead it validate the tables in brazilian-e-commerce-team-3.BET_Team3 dataset that was previously generated by Meltano.

*** No changes are required to any of the python scripts used  ***

2.1) gx_table_validation.py
Called by dagster as a sub-process to validate the tables in brazilian-e-commerce-team-3.BET_Team3 dataset that was generated by Meltano.

Use /dagster/gx/gx_olist_validation.py to run the GX checkpoint

```bash
# gx_table_validation.py

import sys
import os

# Add parent directory to sys.path
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, parent_dir)

from gx_olist_validation import run_checkpoint

def main():

    # %%
    tgt = 'customers'
    mod_name = "gxe_01_olist_customers_suite"
    func_name = "build_expectations_gxe_01_olist_customers_suite"
    run_checkpoint(tgt, mod_name, func_name)

    ....
    ....

if __name__ == "__main__":
    main()

```
### Test GX Validate Meltano
Even though no changes are required, do test, debug and ensure that this GX validation can execute correctly before going to the next stage.
  ```bash
bash

cd <your path>/dagster/gx/dataset
python gx_table_validation.py

```
### 3) DBT
All files relating to DBT are located at <your path>/dagster/GX_DBT_Test

  ```bash
bash
cd <your path>/dagster/GX_DBT_Test
```

3.1) profiles.yml:

a) Replace project (currently lkk-dsai)

b) Replace dataset (currently GX_DBT_Test)

c) Replace keyfile (currently JSON from service account that can access lkk-dsai)

*** Make sure JSON in the keyfile is from the service account that can access the BQ project and dataset ***

  ```bash
# profiles.yml

GX_DBT_Test:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: service-account
      project: <your BQ project id>
      dataset: <your BQ dataset name>
      threads: 1
      location: US
      keyfile: <your path>/<your BQ service account>.json
```


3.2) dbt_project.yml:

```bash
# dbt_project.yml

models:
  GX_DBT_Test:
    dim_customer_100:
      +materialized: table
```


3.3) /dagster/GX_DBT_Test/models/dim_customer_100.sql

a) select data from <your BQ project id>.<your BQ dataset>.customer_100 which was created by Meltano. 

Current setting is lkk-dsai.GX_Meltano_Test.customer_100

```bash
# dim_customer_100.sql

SELECT *
FROM `<your BQ project id>.<your BQ dataset name>.customer_100`
LIMIT 100
```

3.4) /dagster/GX_DBT_Test/models/schema.yml

name must match the schema in dbt_project.yml. 

Columns are defined in the <your BQ project id>.<your BQ project id>.customer_100. 

```bash
# schema.yml

models:
  - name: dim_customer_100
    description: "Customer dimension with city and state"
    columns:
      - name: customer_id
        description: "Primary key - unique identifier for customer"
        tests: [unique, not_null]
      - name: customer_unique_id
        description: "Anonymized customer ID"
      - name: customer_city
        description: "City of the customer"
      - name: customer_state
        description: "State of the customer"
      - name: customer_zip_code_prefix
        description: "ZIP code prefix of the customer"
        tests:
          - not_null
```
### Test DBT
After making changes to the above, it is very important to test and debug your meltano before going to the next stage.

  ```bash
bash

cd <your path>/dagster/GX_DBT_Test
dbt debug
dbt run
dbt test
dbt docs generate
dbt docs serve
```

### 4) GX Dim & Fact Tables Validation.
All files relating to the validation of DBT dim and fact tables are located at <your path>/dagster/gx/dim

  ```bash
bash
cd <your path>/dagster/gx/dim
```

The script for GX does not validate the customer_100 dim table that you had created above.

Instead it validate the dim and fact tables in brazilian-e-commerce-team-3.BET_Team3 that was previously generated by DBT.

*** No changes are required to any of the python scripts used  ***

3.2) /dagster/gx/dim/gx_dim_fact_validation.py

Called by dagster as a sub-process to validate the dim and fact tables in brazilian-e-commerce-team-3.BET_Team3 dataset that was generated by DBT.

Use /dagster/gx/gx_olist_validation.py to run the GX checkpoint

```bash
# gx_dim_fact_validation.py

import sys
import os

# Add parent directory to sys.path
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, parent_dir)

from gx_olist_validation import run_checkpoint

def main():

    # %%
    tgt = 'dim_customers'
    mod_name = "gxe_01_olist_dim_customers_suite"
    func_name = "build_expectations_gxe_01_olist_dim_customers_suite"
    run_checkpoint(tgt, mod_name, func_name)

    ....
    ....

if __name__ == "__main__":
    main()
```

### Test GX Validate DBT
Even though no changes are required, do test, debug and ensure that this GX validation can execute correctly before going to the next stage.

  ```bash
bash

cd <your path>/dagster/gx/dim
python gx_dim_fact_validation.py

```

### 5) Dagster
Now that all 4 components have been verifited to be working correctly individually, we can pull them together as Dagster assets and line them up to execute automatically as an ELT pipeline.

Uses the 4 assets to form this lineage: meltano_csv_to_bigquery -> GX_validate_meltano -> dbt_run -> GX_validate_dbt

All files relating to the Dagster orchestration are located at <your path>/dagster/my_dagster_project/my_dagster_project

  ```bash
bash
cd <your path>/dagster/my_dagster_project/my_dagster_project
```

5.1) assets.py

Defines the 4 assets used in the lineage.  Uses sub-process to execute.

5.1.1) meltano_csv_to_bigquery: 

Execute "meltano run tap-csv target-bigquery" from the full path defined in cwd.  

Replace cwd with the full path of Meltano working directory (<your path>/dagster/GX_Meltano_Test).

```bash
# assets.py

@asset
def meltano_csv_to_bigquery(context: AssetExecutionContext):
    """Runs Meltano pipeline to move data from CSV to BigQuery."""
    try:
        result = subprocess.run(
            ["meltano", "run", "tap-csv", "target-bigquery"],
            cwd = "/Users/luikk/Brazilian-E-Commerce-Team-3-Org/Dagster/GX_Meltano_Test",
            check=True,
            capture_output=True,
            text=True
        )
        context.log.info(result.stdout)
    except subprocess.CalledProcessError as e:
        context.log.error(e.stderr)
        raise
```

5.1.2) GX_validate_meltano:

It is dependent on meltano_csv_to_bigquery to be materialised.

Execute "python gx_table_validation.py" from the full path defined in cwd.

Replace cwd with the full path to gx_table_validation.py (<your path>/dagster/gx/dataset).

```bash
# assets.py

@asset(deps=[meltano_csv_to_bigquery])
def GX_validate_meltano():
    """Runs GX validation after meltano"""
    try:
        subprocess.run(
            ["python", "gx_table_validation.py"], 
            cwd="/Users/luikk/Brazilian-E-Commerce-Team-3-Org/Dagster/gx/dataset",
            check=True
        )
    except subprocess.CalledProcessError as e:
        raise Exception(f"GX after Meltano run failed: {e}")
```

5.1.3) run_dbt:

It is dependent on GX_validate_meltano to be materialised.

Execute "dbt run --project-dir /Users/luikk/Brazilian-E-Commerce-Team-3-Org/dagster/GX_DBT_Test"

Replace the path with "<your path>/dagster/GX_DBT_Test"

Replace cwd with the full path to DBT working directory (<your path>/dagster/GX_DBT_Test).

```bash
# assets.py

@asset(deps=[GX_validate_meltano])
def dbt_run():
    """Runs dbt run"""
    try:
        subprocess.run(["dbt", "run", "--project-dir", "/Users/luikk/Brazilian-E-Commerce-Team-3-Org/Dagster/GX_DBT_Test"], 
                       check=True, 
                       cwd="/Users/luikk/Brazilian-E-Commerce-Team-3-Org/Dagster/GX_DBT_Test/"
        )
    except subprocess.CalledProcessError as e:
        raise Exception(f"DBT run failed: {e}")
```

5.1.4) GX_validate_dbt:

It is dependent on run_dbt to be materialised.

Execute "python gx_dim_fact_validation.py" from the full path defined in cwd.

Replace cwd with the full path to gx_dim_fact_validation.py (<your path>/dagster/gx/dim).

```bash
# assets.py

@asset(deps=[dbt_run])
def GX_validate_dbt():
    """Runs GX validation after dbt"""
    try:
        subprocess.run(
            ["python", "gx_dim_fact_validation.py"], 
            cwd="/Users/luikk/Brazilian-E-Commerce-Team-3-Org/Dagster/gx/dim",
            check=True
        )
    except subprocess.CalledProcessError as e:
        raise Exception(f"GX after Meltano run failed: {e}")
```

5.2) /dagster/my_dagster_project/my_dagster_project/__init__.py

Import the 4 assets from assets.py and define them for use by dagster

```bash
# __init__.py

from dagster import Definitions
from my_dagster_project.assets import meltano_csv_to_bigquery, GX_validate_meltano, dbt_run, GX_validate_dbt

defs = Definitions(
    assets=[meltano_csv_to_bigquery, GX_validate_meltano, dbt_run, GX_validate_dbt],
)
```

# Running Dagster:

```bash
conda activate elt

cd <your path>/dagster/my_dagster_project

dagster dev

<open browser http://127.0.0.1:3000>

<Assets->View Lineage->Materialised all>
```

Author: Lui KK

Version v1.1

Date: 21 Jun 2025
